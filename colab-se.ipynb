{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **SEMANTIC SEGMENTATION**","metadata":{}},{"cell_type":"markdown","source":"**Devices**","metadata":{}},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:50:57.037004Z","iopub.execute_input":"2024-04-07T17:50:57.037515Z","iopub.status.idle":"2024-04-07T17:51:11.736065Z","shell.execute_reply.started":"2024-04-07T17:50:57.037482Z","shell.execute_reply":"2024-04-07T17:51:11.734840Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-07 17:50:59.145301: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-07 17:50:59.145438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-07 17:50:59.285584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 2958070907211393889\nxla_global_id: -1\n]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Imports**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom glob import glob\nimport cv2\nimport albumentations as A\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.transform import resize\nfrom tensorflow.keras.saving import load_model\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Lambda\nfrom tensorflow.keras.metrics import MeanIoU\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:51:11.738755Z","iopub.execute_input":"2024-04-07T17:51:11.739570Z","iopub.status.idle":"2024-04-07T17:51:13.598043Z","shell.execute_reply.started":"2024-04-07T17:51:11.739525Z","shell.execute_reply":"2024-04-07T17:51:13.596818Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:51:13.599524Z","iopub.execute_input":"2024-04-07T17:51:13.600318Z","iopub.status.idle":"2024-04-07T17:51:13.606320Z","shell.execute_reply.started":"2024-04-07T17:51:13.600275Z","shell.execute_reply":"2024-04-07T17:51:13.605187Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## **DATASET**","metadata":{}},{"cell_type":"code","source":"H, W = 192, 192\nnum_patches = 21*32\nshape = (H, W, 3)\nnum_classes = 23\nlr = 1e-4\nbatch_size = 1\nepochs = 30","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:51:13.609643Z","iopub.execute_input":"2024-04-07T17:51:13.610170Z","iopub.status.idle":"2024-04-07T17:51:13.618086Z","shell.execute_reply.started":"2024-04-07T17:51:13.610127Z","shell.execute_reply":"2024-04-07T17:51:13.616995Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:51:13.619742Z","iopub.execute_input":"2024-04-07T17:51:13.620127Z","iopub.status.idle":"2024-04-07T17:51:13.629435Z","shell.execute_reply.started":"2024-04-07T17:51:13.620098Z","shell.execute_reply":"2024-04-07T17:51:13.627901Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"image_path = '/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images'\nlabel_path = '/kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic'\n\ndef create_dataframe(path):\n    name = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            name.append(filename.split('.')[0])\n\n    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n\ndf_images = create_dataframe(image_path)\ndf_masks = create_dataframe(label_path)\nprint('Total Images: ', len(df_images))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:53:18.670054Z","iopub.execute_input":"2024-04-07T17:53:18.670504Z","iopub.status.idle":"2024-04-07T17:53:18.980774Z","shell.execute_reply.started":"2024-04-07T17:53:18.670474Z","shell.execute_reply":"2024-04-07T17:53:18.979651Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Total Images:  400\n","output_type":"stream"}]},{"cell_type":"code","source":"X_trainval, X_test = train_test_split(df_images['id'], test_size=0.1)\nX_train, X_val = train_test_split(X_trainval, test_size=0.2)\n\nprint(f\"Train Size : {len(X_train)} images\")\nprint(f\"Val Size   :  {len(X_val)} images\")\nprint(f\"Test Size  :  {len(X_test)} images\")\n\ny_train = X_train\ny_test = X_test\ny_val = X_val\n\nimg_train = [os.path.join(image_path, f\"{name}.jpg\") for name in X_train]\nmask_train = [os.path.join(label_path, f\"{name}.png\") for name in y_train]\nimg_val = [os.path.join(image_path, f\"{name}.jpg\") for name in X_val]\nmask_val = [os.path.join(label_path, f\"{name}.png\") for name in y_val]\nimg_test = [os.path.join(image_path, f\"{name}.jpg\") for name in X_test]\nmask_test = [os.path.join(label_path, f\"{name}.png\") for name in y_test]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:53:22.421544Z","iopub.execute_input":"2024-04-07T17:53:22.422675Z","iopub.status.idle":"2024-04-07T17:53:22.440360Z","shell.execute_reply.started":"2024-04-07T17:53:22.422614Z","shell.execute_reply":"2024-04-07T17:53:22.439079Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Train Size : 288 images\nVal Size   :  72 images\nTest Size  :  40 images\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_images(image_path, mask_path):\n    '''Reads an image and its corresponding mask from their file paths.'''\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask, channels=1)\n\n    return image, mask\n\n\ndef pad_image(image, mask):\n    '''Pads the image and mask with constant values to ensure consistent dimensions.'''\n    image = tf.pad(image, [[16, 16], [72, 72], [0, 0]], constant_values=-1)\n    mask = tf.pad(mask, [[16, 16], [72, 72], [0, 0]], constant_values=-1)\n\n    return image, mask\n\n\ndef split_images(image, mask):\n    '''Splits the image and mask into patches of the specified size.'''\n    image_patches = tf.image.extract_patches(image[tf.newaxis, ...], sizes=[1, 192, 192, 1], strides=[1, 192, 192, 1], rates=[1, 1, 1, 1], padding='VALID')\n    mask_patches = tf.image.extract_patches(mask[tf.newaxis, ...], sizes=[1, 192, 192, 1], strides=[1, 192, 192, 1], rates=[1, 1, 1, 1], padding='VALID')\n    image_patches = tf.reshape(image_patches, (-1, 192, 192, 3))\n    mask_patches = tf.reshape(mask_patches, (-1, 192, 192, 1))\n\n    return image_patches, mask_patches\n\n\ndef save_images(image_patches, mask_patches, image_dir, mask_dir, name):\n    '''Saves all the image and mask patches to specified directory.'''\n    ROWS = 21\n    COLS = 32\n\n    for i, (image_patch, mask_patch) in enumerate(zip(image_patches, mask_patches)):\n\n        image_patch = tf.cast(image_patch, tf.uint8)\n        mask_patch = tf.cast(mask_patch, tf.uint8)\n\n        image_filename = os.path.join(image_dir, f\"{name:3}_{i//COLS}_{i%COLS}.jpg\")\n        mask_filename = os.path.join(mask_dir, f\"{name:3}_{i//COLS}_{i%COLS}.png\")\n\n        tf.io.write_file(image_filename, tf.image.encode_png(image_patch))\n        tf.io.write_file(mask_filename, tf.image.encode_png(mask_patch))\n\n\ndef create_new_dataset(output_dir, img_data, mask_data):\n    '''Function encapsulates the entire process of reading in the original images, padding, splitting and saving the patches.'''\n    image_dir, mask_dir = os.path.join(output_dir, 'images'), os.path.join(output_dir, 'masks')\n    create_dir(image_dir)\n    create_dir(mask_dir)\n\n    for i, (image_path, mask_path) in tqdm(enumerate(zip(img_data, mask_data)), total=len(img_data)):\n        image, mask = read_images(image_path, mask_path)\n        image, mask = pad_image(image, mask)\n        image_patches, mask_patches = split_images(image, mask)\n        save_images(image_patches, mask_patches, image_dir, mask_dir, i)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:53:30.213464Z","iopub.execute_input":"2024-04-07T17:53:30.213850Z","iopub.status.idle":"2024-04-07T17:53:30.230357Z","shell.execute_reply.started":"2024-04-07T17:53:30.213821Z","shell.execute_reply":"2024-04-07T17:53:30.228526Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%%time\ncreate_new_dataset('/kaggle/working/dataset/train', img_train, mask_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:54:24.054774Z","iopub.execute_input":"2024-04-07T17:54:24.055597Z","iopub.status.idle":"2024-04-07T19:13:30.907185Z","shell.execute_reply.started":"2024-04-07T17:54:24.055554Z","shell.execute_reply":"2024-04-07T19:13:30.905251Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 288/288 [1:19:06<00:00, 16.48s/it]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 1h 31min 13s, sys: 1min 51s, total: 1h 33min 5s\nWall time: 1h 19min 6s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ncreate_new_dataset('/kaggle/working/dataset/val', img_val, mask_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T19:13:36.605392Z","iopub.execute_input":"2024-04-07T19:13:36.606127Z","iopub.status.idle":"2024-04-07T19:33:42.052982Z","shell.execute_reply.started":"2024-04-07T19:13:36.605972Z","shell.execute_reply":"2024-04-07T19:33:42.050846Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 72/72 [20:05<00:00, 16.74s/it]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 23min 4s, sys: 34.2 s, total: 23min 38s\nWall time: 20min 5s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ncreate_new_dataset('/kaggle/working/dataset/test', img_test, mask_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T19:33:42.054685Z","iopub.execute_input":"2024-04-07T19:33:42.055064Z","iopub.status.idle":"2024-04-07T19:44:59.151404Z","shell.execute_reply.started":"2024-04-07T19:33:42.055025Z","shell.execute_reply":"2024-04-07T19:44:59.150158Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 40/40 [11:17<00:00, 16.93s/it]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 12min 54s, sys: 19.5 s, total: 13min 13s\nWall time: 11min 17s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('dataset', 'zip', '/kaggle/working/dataset')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T19:51:55.518814Z","iopub.execute_input":"2024-04-07T19:51:55.519905Z","iopub.status.idle":"2024-04-07T19:58:16.773436Z","shell.execute_reply.started":"2024-04-07T19:51:55.519859Z","shell.execute_reply":"2024-04-07T19:58:16.771531Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1776\u001b[0m, in \u001b[0;36mZipFile.write\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m-> 1776\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:198\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1141\u001b[0m, in \u001b[0;36m_ZipWriteFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m-> 1141\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nbytes\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1009\u001b[0m, in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[1;32m   1008\u001b[0m arcname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(arcdirpath, name)\n\u001b[0;32m-> 1009\u001b[0m \u001b[43mzf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1775\u001b[0m, in \u001b[0;36mZipFile.write\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[1;32m   1776\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(src, dest, \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1153\u001b[0m, in \u001b[0;36m_ZipWriteFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zinfo\u001b[38;5;241m.\u001b[39mcompress_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1839\u001b[0m, in \u001b[0;36mZipFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_dir)\n\u001b[0;32m-> 1839\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_end_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1894\u001b[0m, in \u001b[0;36mZipFile._write_end_record\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1886\u001b[0m centdir \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(structCentralDir,\n\u001b[1;32m   1887\u001b[0m                       stringCentralDir, create_version,\n\u001b[1;32m   1888\u001b[0m                       zinfo\u001b[38;5;241m.\u001b[39mcreate_system, extract_version, zinfo\u001b[38;5;241m.\u001b[39mreserved,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1892\u001b[0m                       \u001b[38;5;241m0\u001b[39m, zinfo\u001b[38;5;241m.\u001b[39minternal_attr, zinfo\u001b[38;5;241m.\u001b[39mexternal_attr,\n\u001b[1;32m   1893\u001b[0m                       header_offset)\n\u001b[0;32m-> 1894\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mwrite(filename)\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1124\u001b[0m, in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             os\u001b[38;5;241m.\u001b[39mchdir(root_dir)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:983\u001b[0m, in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[1;32m    979\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and adding \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to it\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    980\u001b[0m                 zip_filename, base_dir)\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dry_run:\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    984\u001b[0m                          compression\u001b[38;5;241m=\u001b[39mzipfile\u001b[38;5;241m.\u001b[39mZIP_DEFLATED) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[1;32m    985\u001b[0m         arcname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(base_dir)\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m root_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1312\u001b[0m, in \u001b[0;36mZipFile.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[0;32m-> 1312\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1843\u001b[0m, in \u001b[0;36mZipFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1841\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1843\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fpclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1943\u001b[0m, in \u001b[0;36mZipFile._fpclose\u001b[0;34m(self, fp)\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileRefCnt \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileRefCnt \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filePassed:\n\u001b[0;32m-> 1943\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"],"ename":"OSError","evalue":"[Errno 28] No space left on device","output_type":"error"}]},{"cell_type":"code","source":"! pip install kaggle","metadata":{"execution":{"iopub.status.busy":"2024-04-07T19:58:55.171962Z","iopub.execute_input":"2024-04-07T19:58:55.172496Z","iopub.status.idle":"2024-04-07T19:59:09.567570Z","shell.execute_reply.started":"2024-04-07T19:58:55.172462Z","shell.execute_reply":"2024-04-07T19:59:09.566127Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.6.6)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle) (2024.2.2)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.1.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"! kaggle datasets download -d mrandes/dataset-name -p /path/to/download","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/kaggle/input/', 'zip', '/kaggle/working/dataset/')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:38:57.480616Z","iopub.execute_input":"2024-04-07T20:38:57.481938Z","iopub.status.idle":"2024-04-07T20:38:57.632941Z","shell.execute_reply.started":"2024-04-07T20:38:57.481890Z","shell.execute_reply":"2024-04-07T20:38:57.630612Z"},"trusted":true},"execution_count":37,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/dataset/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1124\u001b[0m, in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             os\u001b[38;5;241m.\u001b[39mchdir(root_dir)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:983\u001b[0m, in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[1;32m    979\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and adding \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to it\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    980\u001b[0m                 zip_filename, base_dir)\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dry_run:\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZIP_DEFLATED\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[1;32m    985\u001b[0m         arcname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(base_dir)\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m root_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1251\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/.zip'"],"ename":"OSError","evalue":"[Errno 30] Read-only file system: '/kaggle/input/.zip'","output_type":"error"}]},{"cell_type":"markdown","source":"## **MODEL EXPERIMENTATION**","metadata":{}},{"cell_type":"code","source":"epochs = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### UNET","metadata":{}},{"cell_type":"code","source":"from skimage import io\n\nimage = io.imread('https://github.com/qubvel/segmentation_models/raw/master/images/unet.png')\nplt.imshow(image)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def contracting_path(x, filters):\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)\n    pool = MaxPooling2D((2, 2))(conv)\n    return conv, pool\n\ndef expanding_path(x, skip_connections, filters):\n    up = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(x)\n    cat = concatenate([up, skip_connections])\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(cat)\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)\n    return conv\n\ndef build_unet(input_shape=shape, num_classes=num_classes):\n\n    inputs = Input(input_shape)\n\n    c1, p1 = contracting_path(inputs, 16)\n    c2, p2 = contracting_path(p1, 32)\n    c3, p3 = contracting_path(p2, 64)\n    c4, p4 = contracting_path(p3, 128)\n\n    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(p4)\n    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n\n    u4 = expanding_path(c5, c4, 128)\n    u3 = expanding_path(u4, c3, 64)\n    u2 = expanding_path(u3, c2, 32)\n    u1 = expanding_path(u2, c1, 16)\n\n    outputs = Conv2D(1, (1, 1), padding='same', activation='softmax')(u1)\n\n    model = Model (inputs=inputs, outputs=outputs)\n\n    return model\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet = build_unet()\n\nunet.compile(loss=\"categorical_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(lr),\n              metrics=['accuracy']\n              )\nunet.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}